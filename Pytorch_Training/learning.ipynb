{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Profiler used to trace the memory for CPU and GPU during training and inference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "model = models.resnet18()\n",
    "inputs = torch.randn(5, 3, 224, 224)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "    \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "register_buffer allows for parameters to be saved and restored in the state_dict, they will not be trained by the optimizer.\n",
    "\n",
    "They won't be returned in model.parameters().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layer = nn.Linear(1,1)\n",
    "        \n",
    "        const_val = torch.Tensor([2])\n",
    "        self.register_buffer('constant', const_val, persistent=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x * self.constant\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "model = Model()\n",
    "\n",
    "model(torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storage() is used for finding the real storage of x in RAM which prints dtype and size\n",
    "The storage object can be saved in a variable to see its type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 10, (3, 3))\n",
    "print(x)\n",
    "# x = x.as_strided(size=(4, 5), stride=(1,1))\n",
    "x_t = x.transpose(0,1)\n",
    "id(x_t.storage()) == id(x.storage())\n",
    "print(x.storage(),  x_t.storage())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stride() is a property that determines how many elements should be skipped over in the storage array in order to get the next element in a given dimension in the ORIGINAL tensor, this means the tensor can be transposed and this property looks at the original tensor rather than the transposed tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on a 3 x 3 tensor\n",
    "ex: tensor([[5, 7, 4],\n",
    "            [1, 3, 2],\n",
    "            [7, 3, 8]]) \n",
    "        \n",
    "using stride=(3,1) offset=1 \n",
    "\n",
    "[6,5,7,4,1,3,2,7,3,8]\n",
    " ^ = offset would move 1 column over to start\n",
    "[6,5,7,4,1,3,2,7,3,8]\n",
    "     ^=stride[1]=1 column over from 5 to 7\n",
    "[6,5,7,4,1,3,2,7,3,8]\n",
    "         ^=then move 3 rows from 5 to 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.as_strided(size=(5,5), stride=(1,1))\n",
    "print(x)\n",
    "x = x.as_strided(size=(5,5), stride=(2,0))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.as_strided(size=(a,a), stride=(b,c))\n",
    "This can be thought of as a flatten: \n",
    "\n",
    "tensor([57,1,75,62,97,61,19,85,40,28,90,19,58,40,6,78,39,36,45,62,37,77,16,79,75,10,84,22,23,66])\n",
    "\n",
    "followed by selecting the shape[0](a) then a stride=c selecting the shape[0](a):\n",
    "\n",
    "[[57,1,75,626,62,97,61], [1,75,626,62,97,61,19],...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather() is an advanced indexing function\n",
    "\n",
    "pass indexing dimension and size of the output to gather() it is the equivalent to doing:\n",
    "torch.Tensor([\n",
    "    [tensor[index[0,0],0], tensor[index[0,1],1]],\n",
    "    [tensor[index[1,0],0], tensor[index[1,1],1]] \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor([\n",
    "[57,  1, 75, 62, 97, 61],\n",
    "[19, 85, 40, 28, 90, 19],\n",
    "[58, 40,  6, 78, 39, 36],\n",
    "[45, 62, 37, 77, 16, 79],\n",
    "[75, 10, 84, 22, 23, 66]\n",
    "])\n",
    "index = torch.Tensor([[1,2],[3,4]]).type(torch.int64)\n",
    "tensor.gather(dim=0, index=index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"markdown","metadata":{},"source":["Creating a NN for image recognition\n","Utilizing PyTorch and the FashionMNIST data set for the initial learning phase\n","\n","Data sets chosen and modules imported"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch;\n","from torch import nn;\n","from torch.utils.data import DataLoader;\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor;\n","from torchvision.transforms import v2;\n","\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Data loaded and batch size selected for initial iterable"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 64\n","\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N,C,H,W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["Neural Network class inheriting from nn.Module. \n","\n","Layers defined in the __init__ function and data passing is specified in the forward function\n","\n","For computation purposes the operations are run through MPS if available"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = (\n","    \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{},"source":["Loss function and optimizer defined:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"]},{"cell_type":"markdown","metadata":{},"source":["Train function, takes in data, model, loss function and the optimizer\n","\n","Backpropogation for error reduction\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(dataloader, model, loss_function, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        \n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_function(pred, y)\n","        \n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        \n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch+1) * len(X)\n","            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"]},{"cell_type":"markdown","metadata":{},"source":["Test Function takes in data, model and loss function\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test(dataloader, model, loss_function):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_function(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","        test_loss /= num_batches\n","        correct /= size\n","        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg Loss: {test_loss:>8f} \\n\")"]},{"cell_type":"markdown","metadata":{},"source":["Model settings for runs and prints for each run"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 20\n","for t in range(epochs):\n","    print(f\"Epoch {t+1} \\n ---------------------------\")\n","    train(train_dataloader, model, loss_func, optimizer)\n","    test(test_dataloader, model, loss_func)\n","print(\"Done!\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
